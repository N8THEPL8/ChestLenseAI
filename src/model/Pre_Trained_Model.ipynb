{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcs9ia7A_O1f",
        "outputId": "0e558d95-8a64-4fdf-f49b-e30e61049762"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from torch.optim import SGD\n",
        "from skimage import io as skio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import cv2 as cv\n",
        "import os\n",
        "import base64\n",
        "import json\n",
        "import io\n",
        "import torchxrayvision\n",
        "from pandas import Index\n",
        "import torchxrayvision as xrv\n",
        "import skimage\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import cv2 as cv\n",
        "from PIL import Image\n",
        "from datetime import datetime, date\n",
        "import json\n",
        "import skimage.io as skio\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from collections import OrderedDict\n",
        "from sklearn.metrics import roc_curve, auc, f1_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from tabulate import tabulate\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrJCgGT8OFUy"
      },
      "outputs": [],
      "source": [
        "#Server has of 4 GPU, manually set to avoid multiple models going to same GPU\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '2'  # Use GPU 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfI0olQgwhEz"
      },
      "outputs": [],
      "source": [
        "#Creates Dataset form MIMIC images\n",
        "class MIMIC_Dataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        " \n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
        "        img = skimage.io.imread(img_path + \".jpg\") \n",
        "        img = xrv.datasets.normalize(img, 255)  \n",
        " \n",
        "        # Check that images are 2D arrays\n",
        "        if len(img.shape) > 2:\n",
        "            img = img[:, :, 0]\n",
        "        if len(img.shape) < 2:\n",
        "            print(\"error, dimension lower than 2 for image\")\n",
        " \n",
        "        # Add color channel\n",
        "        img = img[None, :, :]\n",
        "        \n",
        "        transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(), xrv.datasets.XRayResizer(224)])\n",
        " \n",
        "        image = transform(img)\n",
        "        image = torch.from_numpy(image).to(device)\n",
        " \n",
        "        results = []\n",
        " \n",
        "        # Atelectasis\n",
        "        results.append(int(self.annotations.iloc[index, 12] == 1.0))\n",
        " \n",
        "        # Cardiomegaly\n",
        "        results.append(int(self.annotations.iloc[index, 13] == 1.0))\n",
        " \n",
        "        # Consolidation\n",
        "        results.append(int(self.annotations.iloc[index, 14] == 1.0))\n",
        " \n",
        "        # Edema\n",
        "        results.append(int(self.annotations.iloc[index, 15] == 1.0))\n",
        " \n",
        "        # No Finding\n",
        "        results.append(int(self.annotations.iloc[index, 20] == 1.0))\n",
        " \n",
        "        # Pleural Effusion\n",
        "        results.append(int(self.annotations.iloc[index, 21] == 1.0))\n",
        " \n",
        "        y_label = torch.tensor(results, dtype=torch.float32)\n",
        "        \n",
        " \n",
        "\n",
        "        return image, y_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Overalys mask on image used for Grad Cam\n",
        "def show_cam_on_image(img, mask, use_rgb=True, alpha=0.5):\n",
        "    # Convert Image object to NumPy array\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    # Check if img_array is a valid array\n",
        "    if img_array.size == 0:\n",
        "        raise ValueError(\"Invalid input array: img must be a non-empty NumPy array.\")\n",
        "\n",
        "    # Convert mask to a heatmap\n",
        "    heatmap = cv.applyColorMap(np.uint8(255 * mask), cv.COLORMAP_JET)\n",
        "    if use_rgb:\n",
        "        heatmap = cv.cvtColor(heatmap, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize heatmap to match img_array dimensions\n",
        "    if img_array.shape[:2] != heatmap.shape[:2]:\n",
        "        heatmap = cv.resize(heatmap, (img_array.shape[1], img_array.shape[0]))\n",
        "\n",
        "    # Ensure heatmap is of the same type as img_array\n",
        "    img_array = np.uint8(img) \n",
        "    heatmap = np.uint8(heatmap)\n",
        "\n",
        "    # Blend the heatmap with the original image\n",
        "    overlayed_img = cv.addWeighted(img_array, 1 - alpha, heatmap, alpha, 0)\n",
        "    return overlayed_img\n",
        "\n",
        "\n",
        "\n",
        "#Function used to create a Grad-Cam image for a specific disease \n",
        "def generate_gradcam(model, input_tensor, original_image_path, target_category=None):\n",
        "\n",
        "    #target_layers = model.features.denseblock4.denselayer16.conv2 #previously used layer\n",
        "    #select last layer of the model\n",
        "    target_layers = model.features[-1]\n",
        "\n",
        "    # Initialize Grad-CAM with the specified target layers\n",
        "    cam = GradCAM(model=model, target_layers=[target_layers])\n",
        "\n",
        "    # Define targets based on the specified target category\n",
        "    targets = [ClassifierOutputTarget(target_category)] if target_category is not None else None\n",
        "\n",
        "    # Generate CAM mask\n",
        "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
        "\n",
        "    # Load the original image\n",
        "    original_image = Image.open(original_image_path).convert('RGB')\n",
        "\n",
        "    # Create visualization with the specified alpha for the overlay transparency\n",
        "    visualization = show_cam_on_image(original_image, grayscale_cam, use_rgb=True, alpha=0.3) \n",
        "\n",
        "    return visualization\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnNrsbgAJ--6"
      },
      "outputs": [],
      "source": [
        "#Computes performance metrics for each disease\n",
        "#Metrics include AUC, f1, precision, recall and prints ROC\n",
        "#It also produces the optimal thresholds\n",
        "\n",
        "def analyze_model(data_loader, model, device):\n",
        "    \n",
        "    diseaseNames = [\"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"No Finding\", \"Pleural Effusion\"]\n",
        "    bestThresholds = []\n",
        " \n",
        "    true_labels = []\n",
        "    predicted_probs = []\n",
        " \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        " \n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        " \n",
        "            outputs = model(images)\n",
        " \n",
        "            selected_indexes = [0,10,1,4,7]\n",
        "            selected_probs = outputs[:, selected_indexes]\n",
        "            \n",
        "            # Append No Finding probabilities based on other diseases\n",
        "            no_finding_probs = (1 - selected_probs[:, :-1].max(axis=1).values).reshape(-1, 1)\n",
        "            selected_probs = torch.cat((selected_probs[:, :-1], no_finding_probs, selected_probs[:, -1:]), axis=1)\n",
        " \n",
        "            predicted_probs.append(selected_probs.cpu().numpy())\n",
        "            true_labels.append(labels.cpu().numpy())\n",
        " \n",
        "    predicted_probs = np.concatenate(predicted_probs)\n",
        "    true_labels = np.concatenate(true_labels)\n",
        " \n",
        "    true_labels = np.nan_to_num(true_labels)  # Convert NaN to 0\n",
        " \n",
        "    # Update No Finding labels based on other diseases\n",
        "    no_finding_labels = (true_labels.sum(axis=1) == 0).astype(int)\n",
        "    true_labels = np.insert(true_labels, 4, no_finding_labels, axis=1)  \n",
        " \n",
        "    # Calculate ROC curve, AUC, and F1 score for each disease\n",
        "    for i, disease in enumerate(diseaseNames[:-2]):\n",
        "        binary_true_labels = true_labels[:, i]\n",
        "        pred_probs_i = predicted_probs[:, i].flatten()\n",
        " \n",
        "        binary_true_labels = np.where(binary_true_labels > 0, 1, 0)  # Ensure binary labels\n",
        " \n",
        "        fpr, tpr, thresholds = roc_curve(binary_true_labels, pred_probs_i)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        best_threshold_index = np.argmax(tpr - fpr)\n",
        "        best_threshold = thresholds[best_threshold_index]\n",
        "        bestThresholds.append(best_threshold)\n",
        " \n",
        "        print(f\"{disease}:\")\n",
        "        print(f\"   AUC: {roc_auc:.4f}\")\n",
        "        print(f\"   Best Threshold: {best_threshold:.4f}\")\n",
        " \n",
        "        binary_predictions = (pred_probs_i > best_threshold).astype(int)\n",
        "        precision = precision_score(binary_true_labels, binary_predictions)\n",
        "        recall = recall_score(binary_true_labels, binary_predictions)\n",
        "        f1 = f1_score(binary_true_labels, binary_predictions)\n",
        "        \n",
        "        \n",
        "        plt.plot(fpr, tpr, lw=2, label=f'{diseaseNames[i]} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "        print(f\"{diseaseNames[i]}:\")\n",
        "        print(f\"   AUC: {roc_auc:.4f}\")\n",
        "        print(f\"   Best Threshold: {best_threshold:.4f}\")\n",
        "        print(f\"   Precision: {precision:.4f}\")\n",
        "        print(f\"   Recall: {recall:.4f}\")\n",
        "        print(f\"   F1 Score: {f1:.4f}\\n\")\n",
        "        \n",
        " \n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC)')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        " \n",
        "    return bestThresholds\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx78KHNNKUHX"
      },
      "outputs": [],
      "source": [
        "# Load Validation Set\n",
        "\n",
        "# csv_file_path =  \"/home/group18/Data/mimic/csv/validation/p17.csv\"\n",
        "# root_dir_path = \"/home/group18/Data/mimic/validation/p17\"\n",
        "\n",
        "#Paths for Testing\n",
        "#Folders p18 and p18 must be combined before running\n",
        "csv_file_path =  \"/home/group18/Data/mimic/csv/test/p18_p19.csv\"\n",
        "root_dir_path = \"/home/group18/Data/mimic/test/p18_p19\"\n",
        "\n",
        "data_set = MIMIC_Dataset(csv_file=csv_file_path, root_dir=root_dir_path, transform=transforms.ToTensor())\n",
        "data_loader = DataLoader(dataset=data_set, batch_size=1, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i5nQ9HD-L1kQ",
        "outputId": "8126af40-a3e7-4f99-f472-a7773d85f17a"
      },
      "outputs": [],
      "source": [
        "# # Start Model Validation\n",
        " \n",
        "# #weight_string = \"densenet121-res224-mimic_ch\" #alternative weights\n",
        " \n",
        "# weight_string = \"densenet121-res224-mimic_nb\"\n",
        "# model = xrv.models.get_model(weight_string).to(device)\n",
        " \n",
        "# print(model.pathologies)\n",
        " \n",
        "# model.eval()  # Set to evaluation mode\n",
        " \n",
        "# analyze_model(data_loader, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR8mKRvy-LXg"
      },
      "outputs": [],
      "source": [
        "#Runs our model on a single image and returns disease prediction, true labels and grad cam images\n",
        "\n",
        "def test_single_image(filepath, csv_file_path, thresholds, model):\n",
        "    selected_indexes = [0, 10, 1, 4, 7]\n",
        "    true_labels = []\n",
        "    prediction = []\n",
        "    grad_cam_images = []\n",
        "\n",
        "    img = skimage.io.imread(filepath)\n",
        "    img = xrv.datasets.normalize(img, 255)\n",
        "\n",
        "    # Check that images are 2D arrays\n",
        "    if len(img.shape) > 2:\n",
        "        img = img[:, :, 0]\n",
        "    if len(img.shape) < 2:\n",
        "        print(\"error, dimension lower than 2 for image\")\n",
        "\n",
        "    # Add color channel\n",
        "    img = img[None, :, :]\n",
        "\n",
        "    transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(), xrv.datasets.XRayResizer(224)])\n",
        "\n",
        "    image = transform(img)\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        image = torch.from_numpy(image).unsqueeze(0).to(device)\n",
        "        outputs = model(image)\n",
        "        probability = outputs[0, selected_indexes].cpu().numpy()\n",
        "        print(\"Output: \", outputs)\n",
        "        print(\"Probability: \", probability)\n",
        "\n",
        "    for index in selected_indexes:\n",
        "        grad_cam_image = generate_gradcam(model, image, filepath, index)\n",
        "        grad_cam_images.append(grad_cam_image)\n",
        "\n",
        "    grad_cam_images.insert(4, Image.open(filepath).convert('RGB'))\n",
        "\n",
        "    model.eval()  # Switch back to evaluation mode\n",
        "\n",
        "    # Extract true labels from CSV file\n",
        "    filename_without_extension = os.path.splitext(os.path.basename(filepath))[0]\n",
        "    with open(csv_file_path, 'r') as f:\n",
        "        datareader = csv.reader(f)\n",
        "        for row in datareader:\n",
        "            if row[0] == filename_without_extension:\n",
        "                true_labels.extend([int(float(row[i])) if row[i] == '1.0' else 0 for i in [12, 13, 14, 15, 20, 21]])\n",
        "                break\n",
        "\n",
        "    # Compare predictions and true labels\n",
        "    for i in range(5):\n",
        "        prediction.append(1 if probability[i] >= thresholds[i] else 0)\n",
        "\n",
        "\n",
        "    # If all model predictions are False all set No Finding to 1, else set No Finding to 0 \n",
        "    allZero = True\n",
        "    for i in range(5):\n",
        "        if prediction[i] == 1:\n",
        "            allZero = False\n",
        "            break\n",
        "\n",
        "    if allZero == True:\n",
        "        prediction.insert(4, 1)\n",
        "        probability = probability.astype(object)\n",
        "        probability = np.insert(probability, 4, \"-\")\n",
        "    else:\n",
        "        prediction.insert(4, 0)\n",
        "        probability = probability.astype(object)\n",
        "        probability = np.insert(probability, 4, \"-\")\n",
        "\n",
        "    print(\"probability: \", probability)\n",
        "    print(\"prediction: \", prediction)\n",
        "    print(\"true labels: \", true_labels)\n",
        "\n",
        "    # Create a table for visualization\n",
        "    array1 = ['Atelectasis', probability[0], prediction[0], true_labels[0]]\n",
        "    array2 = ['Cardiomegaly', probability[1], prediction[1], true_labels[1]]\n",
        "    array3 = ['Consolidation', probability[2], prediction[2], true_labels[2]]\n",
        "    array4 = ['Edema', probability[3], prediction[3], true_labels[3]]\n",
        "    array5 = ['No Finding', probability[4], prediction[4], true_labels[4]]\n",
        "    array6 = ['Pleural Effusion', probability[5], prediction[5], true_labels[5]]\n",
        "\n",
        "    table = [['Disease', 'Model Output', 'Model Prediction', 'True Labels'],\n",
        "             array1, array2, array3, array4, array5, array6]\n",
        "\n",
        "    # Print the table\n",
        "    print(\"\\n\")\n",
        "    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\n",
        "\n",
        "    return image, grad_cam_images, prediction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Runs our model on a single image and returns disease prediction and grad cam images\n",
        "\n",
        "def test_single_image_no_csv(filepath, thresholds, model):\n",
        "    selected_indexes = [0, 10, 1, 4, 7]\n",
        "    prediction = []\n",
        "    grad_cam_images = []\n",
        "\n",
        "    img = skimage.io.imread(filepath)\n",
        "    img = xrv.datasets.normalize(img, 255)\n",
        "\n",
        "    # Check that images are 2D arrays\n",
        "    if len(img.shape) > 2:\n",
        "        img = img[:, :, 0]\n",
        "    if len(img.shape) < 2:\n",
        "        print(\"error, dimension lower than 2 for image\")\n",
        "\n",
        "    # Add color channel\n",
        "    img = img[None, :, :]\n",
        "\n",
        "    transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(), xrv.datasets.XRayResizer(224)])\n",
        "\n",
        "    image = transform(img)\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        image = torch.from_numpy(image).unsqueeze(0).to(device)\n",
        "        outputs = model(image)\n",
        "        probability = outputs[0, selected_indexes].cpu().numpy()\n",
        "        print(\"Output: \", outputs)\n",
        "        print(\"Probability: \", probability)\n",
        "\n",
        "    for index in selected_indexes:\n",
        "        grad_cam_image = generate_gradcam(model, image, filepath, index)\n",
        "        grad_cam_images.append(grad_cam_image)\n",
        "\n",
        "    grad_cam_images.insert(4, Image.open(filepath).convert('RGB'))\n",
        "\n",
        "    model.eval()  # Switch back to evaluation mode\n",
        "\n",
        "    # Compare predictions and true labels\n",
        "    for i in range(5):\n",
        "        prediction.append(1 if probability[i] >= thresholds[i] else 0)\n",
        "\n",
        "\n",
        "    # If all model predictions are False all set No Finding to 1, else set No Finding to 0 \n",
        "    allZero = True\n",
        "    for i in range(5):\n",
        "        if prediction[i] == 1:\n",
        "            allZero = False\n",
        "            break\n",
        "\n",
        "    if allZero == True:\n",
        "        prediction.insert(4, 1)\n",
        "        probability = probability.astype(object)\n",
        "        probability = np.insert(probability, 4, \"-\")\n",
        "    else:\n",
        "        prediction.insert(4, 0)\n",
        "        probability = probability.astype(object)\n",
        "        probability = np.insert(probability, 4, \"-\")\n",
        "\n",
        "    print(\"probability: \", probability)\n",
        "    print(\"prediction: \", prediction)\n",
        "\n",
        "    # Create a table for visualization\n",
        "    array1 = ['Atelectasis', probability[0], prediction[0]]\n",
        "    array2 = ['Cardiomegaly', probability[1], prediction[1]]\n",
        "    array3 = ['Consolidation', probability[2], prediction[2]]\n",
        "    array4 = ['Edema', probability[3], prediction[3]]\n",
        "    array5 = ['No Finding', probability[4], prediction[4]]\n",
        "    array6 = ['Pleural Effusion', probability[5], prediction[5]]\n",
        "\n",
        "    table = [['Disease', 'Model Output', 'Model Prediction'],\n",
        "             array1, array2, array3, array4, array5, array6]\n",
        "\n",
        "    # Print the table\n",
        "    print(\"\\n\")\n",
        "    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\n",
        "\n",
        "    return image, grad_cam_images, prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "ZEbbPtyI_Egc",
        "outputId": "4d6b7f0c-0959-4e7f-9903-7ba0a46df493"
      },
      "outputs": [],
      "source": [
        "#Plots original and grad cam image side by side for easy comparison\n",
        "\n",
        "def plot_images(original_image, heatmap_image, disease_name):\n",
        "    # Create a figure with 2 subplots\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # Plot the original image\n",
        "    axs[0].imshow(original_image)\n",
        "    axs[0].set_title('Original Image')\n",
        "    axs[0].axis('off')  # Hide the axes ticks\n",
        "\n",
        "    # Normalize the heatmap image if necessary\n",
        "    if isinstance(heatmap_image, np.ndarray) and heatmap_image.dtype != np.uint8:\n",
        "        heatmap_image = (heatmap_image - heatmap_image.min()) / (heatmap_image.max() - heatmap_image.min())\n",
        "\n",
        "    # Plot the heatmap image\n",
        "    axs[1].imshow(heatmap_image, cmap='hot', alpha=0.5)\n",
        "    axs[1].set_title('Heatmap for ' + disease_name)\n",
        "    axs[1].axis('off')  # Hide the axes ticks\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#These functions are shared between backend and frontend and are used to convert images to byte array so they can be passed in a json\n",
        "\n",
        "\n",
        "#converts JPEG to a byte representation\n",
        "def image_to_base64(image_array):\n",
        "    image = Image.fromarray(np.uint8(image_array)).convert('RGB')\n",
        "    img_byte_arr = io.BytesIO()\n",
        "    image.save(img_byte_arr, format='JPEG')\n",
        "    return base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
        "\n",
        "# Function to preprocess and convert image to byte array\n",
        "def preprocess_and_convert_to_byte_array(image_path):\n",
        "    # Preprocess the image\n",
        "    image = skio.imread(image_path)\n",
        "    RGB = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "    new_image = Image.fromarray(RGB)\n",
        "    new_image = new_image.resize((256, 256))\n",
        "    \n",
        "    # Convert to byte array\n",
        "    img_byte_arr = io.BytesIO()\n",
        "    new_image.save(img_byte_arr, format='JPEG')\n",
        "    img_byte_arr = img_byte_arr.getvalue()\n",
        "    return img_byte_arr\n",
        "\n",
        "# Function to convert byte array back to image\n",
        "def byte_array_to_image(byte_array):\n",
        "    img_byte_arr = io.BytesIO(byte_array)\n",
        "    img = Image.open(img_byte_arr)\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Runs our model on a single image and returns disease prediction, true labels and grad cam images\n",
        "#Then prints and plots results\n",
        "\n",
        "def run_with_csv(filepath, csv_file_path):\n",
        "\n",
        "    weight_string = \"densenet121-res224-mimic_nb\"\n",
        "    model = xrv.models.get_model(weight_string).to(device)\n",
        "    model.eval()  # Set to evaluation mode\n",
        "\n",
        "    #thresholds are old and determine if model predictions are 1 or 0 based on model probability\n",
        "    thresholds = [0.6739513, 0.6078657, 0.514972, 0.55786973, 0.2235725, 0]\n",
        "    diseaseNames = [\"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"No Finding\", \"Pleural Effusion\"]\n",
        "\n",
        "    print(\"thresholds: \", thresholds)\n",
        "\n",
        "    _, grad_cam_image, predictions = test_single_image(filepath, csv_file_path, thresholds, model)\n",
        "\n",
        "    for x in range(0,6):\n",
        "        plot_images(Image.open(filepath).convert(\"RGB\"), grad_cam_image[x], diseaseNames[x])\n",
        "\n",
        "    grad_cam_images_base64 = [image_to_base64(img) for img in grad_cam_image]\n",
        "\n",
        "    diseases_data = []\n",
        "    for i, disease_name in enumerate(diseaseNames):\n",
        "        diseases_data.append({\n",
        "            \"diseaseName\": disease_name,\n",
        "            \"prediction\": predictions[i],\n",
        "            \"gradCamImage\": grad_cam_images_base64[i]\n",
        "        })\n",
        "\n",
        "    data = { \"diseasesData\": diseases_data }\n",
        "\n",
        "    # Convert the structured data to a JSON string\n",
        "    json_data = json.dumps(data, indent=4)\n",
        "\n",
        "    return json_data\n",
        "\n",
        "#img = \"846c4452-a65f37a6-20151e1f-a72bf7d1-8145f163\"\n",
        "img = \"Data/mimic/validation/p17/10d37518-05a99e46-bfd45f28-ef76d3cc-fd929d72.jpg\"\n",
        "#filepath = \"/home/group18/Data/mimic/validation/p17/\" + img + \".jpg\"\n",
        "filepath = \"/home/group18/\" + img\n",
        "csv_file_path = \"/home/group18/Data/mimic/csv/validation/p17.csv\"\n",
        "run_with_csv(filepath, csv_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Runs our model on a single image and returns disease prediction and grad cam images\n",
        "#Then prints and plots results\n",
        "\n",
        "def run_with_no_csv(filepath):\n",
        "\n",
        "    weight_string = \"densenet121-res224-mimic_nb\"\n",
        "    model = xrv.models.get_model(weight_string).to(device)\n",
        "    model.eval()  # Set to evaluation mode\n",
        "\n",
        "    #thresholds are old and determine if model predictions are 1 or 0 based on model probability\n",
        "    thresholds = [0.6739513, 0.6078657, 0.514972, 0.55786973, 0.2235725, 0]\n",
        "    diseaseNames = [\"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"No Finding\", \"Pleural Effusion\"]\n",
        "\n",
        "    print(\"thresholds: \", thresholds)\n",
        "\n",
        "    _, grad_cam_image, predictions = test_single_image_no_csv(filepath, thresholds, model)\n",
        "    \n",
        "    for x in range(0,6):\n",
        "        plot_images(Image.open(filepath).convert(\"RGB\"), grad_cam_image[x], diseaseNames[x])\n",
        "\n",
        "    grad_cam_images_base64 = [image_to_base64(img) for img in grad_cam_image]\n",
        "\n",
        "    predictions[5] = \"NaN\"\n",
        "\n",
        "    diseases_data = []\n",
        "    for i, disease_name in enumerate(diseaseNames):\n",
        "        diseases_data.append({\n",
        "            \"diseaseName\": disease_name,\n",
        "            \"prediction\": predictions[i],\n",
        "            \"gradCamImage\": grad_cam_images_base64[i]\n",
        "        })\n",
        "\n",
        "    data = { \"diseasesData\": diseases_data }\n",
        "\n",
        "    # Convert the structured data to a JSON string\n",
        "    json_data = json.dumps(data, indent=4)\n",
        "\n",
        "    return json_data\n",
        "\n",
        "img = \"846c4452-a65f37a6-20151e1f-a72bf7d1-8145f163\"\n",
        "#img = \"8d797272-59e8e04b-95caf66f-0787a22e-497ec005\"\n",
        "filepath = \"/home/group18/Data/mimic/validation/p17/\" + img + \".jpg\"\n",
        "\n",
        "run_with_no_csv(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##This block is used to test the average run time of the model\n",
        "\n",
        "# total_time = 0\n",
        "\n",
        "\n",
        "# img = \"/home/group18/Data/mimic/test/p18_p19/a73f67cb-036cb1ae-34b24fc2-725883fd-b5961466.jpg\"\n",
        "\n",
        "# #Before testing comment out print statements in run_with_no_csv and test_single_image_no_csv\n",
        "# for x in range (0,20):\n",
        "#     start_time = time.time()\n",
        "#     run_with_no_csv(img)\n",
        "#     end_time = time.time()\n",
        "#     total_time += end_time - start_time\n",
        "\n",
        "# print(\"Average Time in Seconds\", total_time / 20)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
